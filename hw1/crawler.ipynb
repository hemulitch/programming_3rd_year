{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from fake_useragent import UserAgent\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Краулер\n",
    "\n",
    "Для создания датасета я решила собрать отзывы о различных тональных средствах с сайта irecommend.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'User-Agent': 'Mozilla/5.0 (X11; U; Linux i686 (x86_64); nl; rv:1.8.0.6) Gecko/20060728 SUSE/1.5.0.6-1.2 Firefox/1.5.0.6'}\n"
     ]
    }
   ],
   "source": [
    "# чтобы обойти блокировку, притворимся нормальным браузером\n",
    "ua = UserAgent(verify_ssl=False)\n",
    "headers = {'User-Agent': ua.random}\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию errors_handler, обрабатывающую ошибки при парсинге страниц с отзывами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors_handler(page_number, review):\n",
    "\n",
    "    with open('./errors.txt', 'a', encoding='utf-8') as f:\n",
    "        \n",
    "        f.write(f'Ошибка возникла на странице {page_number}\\n')\n",
    "        f.write(f'Текст ревью:\\n {review}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В разделе \"Тональные средства\" на сайте 100 страниц с отзывами. Возьмем 15 из них, по каждой будем проходиться, собирая ссылки на страницы отдельных отзывов и передавая их в функцию get_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(page_number):\n",
    "    \n",
    "    session_page = requests.session()\n",
    "    response = session_page.get(f'https://irecommend.ru/catalog/reviews/30-884?page={page_number}', headers=headers)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    reviews_links = soup.find_all('a', {'class': 'more'})\n",
    "\n",
    "    for review_link in reviews_links:\n",
    "        \n",
    "        get_review(review_link, page_number)\n",
    "\n",
    "    print(f'Page {page_number} has been completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция get_review необходима для парсинга собственно самой страницы с отзывом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review(review_link, page_number):\n",
    "    \n",
    "    global reviews_dict\n",
    "\n",
    "    link = review_link.attrs['href']\n",
    "    url = 'https://irecommend.ru' + link\n",
    "    session_review = requests.session()\n",
    "    req = session_review.get(url, headers={'User-Agent': ua.random})\n",
    "    page = req.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "    # текст отзыва\n",
    "    review = soup.find('div', {'itemprop': 'reviewBody'})\n",
    "    try:\n",
    "        text = review.text\n",
    "        reviews_dict['Отзыв'].append(text)\n",
    "    except AttributeError:\n",
    "        reviews_dict['Отзыв'].append('')\n",
    "        errors_handler(page_number, review)\n",
    "\n",
    "    # оценка \n",
    "    rating = soup.find('meta', {'itemprop': 'ratingValue'})\n",
    "    try:\n",
    "        grade = rating.attrs['content']\n",
    "        reviews_dict['Оценка'].append(grade)\n",
    "    except AttributeError:\n",
    "        reviews_dict['Оценка'].append('')\n",
    "        errors_handler(page_number, review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускаем проход по страницам в цикле:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 0 has been completed\n",
      "Page 1 has been completed\n",
      "Page 2 has been completed\n",
      "Page 3 has been completed\n",
      "Page 4 has been completed\n",
      "Page 5 has been completed\n",
      "Page 6 has been completed\n",
      "Page 7 has been completed\n",
      "Page 8 has been completed\n",
      "Page 9 has been completed\n",
      "Page 10 has been completed\n",
      "Page 11 has been completed\n",
      "Page 12 has been completed\n",
      "Page 13 has been completed\n",
      "Page 14 has been completed\n"
     ]
    }
   ],
   "source": [
    "reviews_dict = {'Отзыв' : [], 'Оценка' : []}\n",
    "for i in range(15):\n",
    "    get_page(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученные результаты сохраняем в формате csv-файла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(reviews_dict)\n",
    "result.to_csv('./result.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
